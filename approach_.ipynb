{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Convolution2D, LocallyConnected2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import load_img, save_img, img_to_array\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (152, 152)\n",
    "\n",
    "#OpenCV haarcascade module\n",
    "\n",
    "opencv_home = cv2.__file__\n",
    "folders = opencv_home.split(os.path.sep)[0:-1]\n",
    "path = folders[0]\n",
    "for folder in folders[1:]:\n",
    "\tpath = path + \"/\" + folder\n",
    "\n",
    "detector_path = path+\"/data/haarcascade_frontalface_default.xml\"\n",
    "\n",
    "if os.path.isfile(detector_path) != True:\n",
    "\traise ValueError(\"Confirm that opencv is installed on your environment! Expected path \",detector_path,\" violated.\")\n",
    "else:\n",
    "\tface_cascade = cv2.CascadeClassifier(detector_path)\n",
    "\n",
    "#-------------------------\n",
    "def detectFace(img_path, target_size=(152, 152)):\n",
    "\t\n",
    "\timg = cv2.imread(img_path)\n",
    "\t\n",
    "\tfaces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "\t\n",
    "\tif len(faces) > 0:\n",
    "\t\tx,y,w,h = faces[0]\n",
    "\t\t\n",
    "\t\tmargin = 0\n",
    "\t\tx_margin = w * margin / 100\n",
    "\t\ty_margin = h * margin / 100\n",
    "\t\t\n",
    "\t\tif y - y_margin > 0 and y+h+y_margin < img.shape[1] and x-x_margin > 0 and x+w+x_margin < img.shape[0]:\n",
    "\t\t\tdetected_face = img[int(y-y_margin):int(y+h+y_margin), int(x-x_margin):int(x+w+x_margin)]\n",
    "\t\telse:\n",
    "\t\t\tdetected_face = img[int(y):int(y+h), int(x):int(x+w)]\n",
    "\t\t\n",
    "\t\tdetected_face = cv2.resize(detected_face, target_size)\n",
    "\t\t\n",
    "\t\timg_pixels = image.img_to_array(detected_face)\n",
    "\t\timg_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "\t\t\n",
    "\t\t#normalize in [0, 1]\n",
    "\t\timg_pixels /= 255 \n",
    "\t\t\n",
    "\t\treturn img_pixels\n",
    "\telse:\n",
    "\t\traise ValueError(\"Face could not be detected in \", img_path,\". Please confirm that the picture is a face photo.\")\n",
    "\n",
    "#-------------------------\n",
    "\n",
    "#DeepFace model\n",
    "base_model = Sequential()\n",
    "base_model.add(Convolution2D(32, (11, 11), activation='relu', name='C1', input_shape=(152, 152, 3)))\n",
    "base_model.add(MaxPooling2D(pool_size=3, strides=2, padding='same', name='M2'))\n",
    "base_model.add(Convolution2D(16, (9, 9), activation='relu', name='C3'))\n",
    "base_model.add(LocallyConnected2D(16, (9, 9), activation='relu', name='L4'))\n",
    "base_model.add(LocallyConnected2D(16, (7, 7), strides=2, activation='relu', name='L5') )\n",
    "base_model.add(LocallyConnected2D(16, (5, 5), activation='relu', name='L6'))\n",
    "base_model.add(Flatten(name='F0'))\n",
    "base_model.add(Dense(4096, activation='relu', name='F7'))\n",
    "base_model.add(Dropout(rate=0.5, name='D0'))\n",
    "base_model.add(Dense(8631, activation='softmax', name='F8'))\n",
    "\n",
    "base_model.load_weights(\"E:/FaceRecognition/VGGFace2_DeepFace_weights_val-0.9034.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop F8 and D0 layers. F7 is the representation layer.\n",
    "model = Model(inputs=base_model.layers[0].input, outputs=base_model.layers[-3].output)\n",
    "\n",
    "#------------------------\n",
    "def l2_normalize(x):\n",
    "\treturn x / np.sqrt(np.sum(np.multiply(x, x)))\n",
    "\n",
    "def findEuclideanDistance(source_representation, test_representation):\n",
    "\teuclidean_distance = source_representation - test_representation\n",
    "\teuclidean_distance = np.sum(np.multiply(euclidean_distance, euclidean_distance))\n",
    "\teuclidean_distance = np.sqrt(euclidean_distance)\n",
    "\treturn euclidean_distance\n",
    "\n",
    "#------------------------\t\n",
    "\n",
    "#put your employee pictures in this path as name_of_employee.jpg\n",
    "employee_pictures = \"database/\"\n",
    "\n",
    "employees = dict()\n",
    "\n",
    "for file in listdir(employee_pictures):\n",
    "\temployee, extension = file.split(\".\")\n",
    "\timg_path = 'database/%s.jpg' % (employee)\n",
    "\timg = detectFace(img_path)\n",
    "\t\n",
    "\trepresentation = model.predict(img)[0]\n",
    "\t\n",
    "\temployees[employee] = representation\n",
    "\t\n",
    "print(\"employee representations retrieved successfully\")\n",
    "\n",
    "#------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0) #webcam\n",
    "\n",
    "while(True):\n",
    "\tret, img = cap.read()\n",
    "\tfaces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "\t\n",
    "\tfor (x,y,w,h) in faces:\n",
    "\t\tif w > 130: #discard small detected faces\n",
    "\t\t\tcv2.rectangle(img, (x,y), (x+w,y+h), (67, 67, 67), 1) #draw rectangle to main image\n",
    "\t\t\t\n",
    "\t\t\tdetected_face = img[int(y):int(y+h), int(x):int(x+w)] #crop detected face\n",
    "\t\t\tdetected_face = cv2.resize(detected_face, target_size) #resize to 152x152\n",
    "\t\t\t\n",
    "\t\t\timg_pixels = image.img_to_array(detected_face)\n",
    "\t\t\timg_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "\t\t\timg_pixels /= 255\n",
    "\t\t\t\n",
    "\t\t\tcaptured_representation = model.predict(img_pixels)[0]\n",
    "\t\t\t\n",
    "\t\t\tdistances = []\n",
    "\t\t\t\n",
    "\t\t\tfor i in employees:\n",
    "\t\t\t\temployee_name = i\n",
    "\t\t\t\tsource_representation = employees[i]\n",
    "\t\t\t\t\n",
    "\t\t\t\tdistance = findEuclideanDistance(l2_normalize(captured_representation), l2_normalize(source_representation))\n",
    "\t\t\t\tdistances.append(distance)\n",
    "\t\t\t\n",
    "\t\t\tis_found = False; index = 0\n",
    "\t\t\tfor i in employees:\n",
    "\t\t\t\temployee_name = i\n",
    "\t\t\t\tif index == np.argmin(distances):\n",
    "\t\t\t\t\tif distances[index] <= 0.70:\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\tprint(\"detected: \",employee_name, \"(\",distances[index],\")\")\n",
    "\t\t\t\t\t\temployee_name = employee_name.replace(\"_\", \"\")\n",
    "\t\t\t\t\t\tsimilarity = distances[index]\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\tis_found = True\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\t\n",
    "\t\t\t\tindex = index + 1\n",
    "\t\t\t\n",
    "\t\t\tif is_found:\n",
    "\t\t\t\tdisplay_img = cv2.imread(\"database/%s.jpg\" % employee_name)\n",
    "\t\t\t\tpivot_img_size = 112\n",
    "\t\t\t\tdisplay_img = cv2.resize(display_img, (pivot_img_size, pivot_img_size))\n",
    "\t\t\t\t\t\t\t\t\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tresolution_x = img.shape[1]; resolution_y = img.shape[0]\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tlabel = employee_name+\" (\"+\"{0:.2f}\".format(similarity)+\")\"\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tif y - pivot_img_size > 0 and x + w + pivot_img_size < resolution_x:\n",
    "\t\t\t\t\t\t#top right\n",
    "\t\t\t\t\t\t#img[y - pivot_img_size:y, x+w:x+w+pivot_img_size] = display_img\n",
    "\t\t\t\t\t\tcv2.putText(img, label, (x+w, y+10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (67,67,67), 1)\t\t\t\t\t\n",
    "\t\t\t\t\telif y + h + pivot_img_size < resolution_y and x - pivot_img_size > 0:\n",
    "\t\t\t\t\t\t#bottom left\n",
    "\t\t\t\t\t\t#img[y+h:y+h+pivot_img_size, x-pivot_img_size:x] = display_img\n",
    "\t\t\t\t\t\tcv2.putText(img, label, (x - pivot_img_size, y+h-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (67,67,67), 1)\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\telif y - pivot_img_size > 0 and x - pivot_img_size > 0:\n",
    "\t\t\t\t\t\t#top left\n",
    "\t\t\t\t\t\t#img[y-pivot_img_size:y, x-pivot_img_size:x] = display_img\n",
    "\t\t\t\t\t\tcv2.putText(img, label, (x - pivot_img_size, y+10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (67,67,67), 1)\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\telif x+w+pivot_img_size < resolution_x and y + h + pivot_img_size < resolution_y:\n",
    "\t\t\t\t\t\t#bottom righ\n",
    "\t\t\t\t\t\t#img[y+h:y+h+pivot_img_size, x+w:x+w+pivot_img_size] = display_img\n",
    "\t\t\t\t\t\tcv2.putText(img, label, (x+w, y+h-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (67,67,67), 1)\n",
    "\t\t\t\t\t\n",
    "\t\t\t\texcept Exception as e:\n",
    "\t\t\t\t\tprint(\"exception occured: \", str(e))\n",
    "\t\t\t\n",
    "\tcv2.imshow('Face Recognition',img)\n",
    "\t\n",
    "\tif cv2.waitKey(1) & 0xFF == ord('q'): #press q to quit\n",
    "\t\tbreak\n",
    "\t\n",
    "#kill open cv things\t\t\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    " \n",
    "#Reference: https://github.com/serengil/tensorflow-101/blob/master/python/fb-deepface-real-time.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "detected:  Siyam ( 0.64850706 )\n",
    "detected:  Siyam ( 0.66643345 )\n",
    "detected:  Siyam ( 0.66823554 )\n",
    "detected:  Siyam ( 0.6681981 )\n",
    "detected:  Siyam ( 0.6516859 )\n",
    "detected:  Siyam ( 0.6170238 )\n",
    "detected:  Siyam ( 0.60369784 )\n",
    "detected:  Siyam ( 0.6137962 )\n",
    "detected:  Siyam ( 0.6226641 )\n",
    "detected:  Siyam ( 0.601211 )\n",
    "detected:  Siyam ( 0.603649 )\n",
    "detected:  Siyam ( 0.60828096 )\n",
    "detected:  Siyam ( 0.638792 )\n",
    "detected:  Siyam ( 0.63273925 )\n",
    "detected:  Siyam ( 0.6397345 )\n",
    "detected:  Siyam ( 0.65797216 )\n",
    "detected:  Siyam ( 0.6353613 )\n",
    "detected:  Siyam ( 0.66956264 )\n",
    "detected:  Siyam ( 0.6415046 )\n",
    "detected:  Siyam ( 0.6368075 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
